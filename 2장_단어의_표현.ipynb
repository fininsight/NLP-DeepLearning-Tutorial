{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2장 단어의 표현",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fininsight/nlp-deeplearning-tutorial/blob/master/2%EC%9E%A5_%EB%8B%A8%EC%96%B4%EC%9D%98_%ED%91%9C%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGRL7KyNPQPk",
        "colab_type": "text"
      },
      "source": [
        "원핫인코딩\n",
        "\n",
        "sklearn에서 원핫인코딩의 입력값으로 숫자형이 들어가야 하기 때문에 \n",
        "\n",
        "LabelEncoder를 사용하여 문자형 변수를 숫자형으로 변경해 준 후 원핫인코딩을 해준다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx1BjReVO1_9",
        "colab_type": "code",
        "outputId": "e796d082-f396-4692-f229-ae761a57ea8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "word_ls = ['원숭이','바나나','사과','코끼리']\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()      \n",
        "onehot_encoder = preprocessing.OneHotEncoder()    # 원핫인코딩\n",
        "\n",
        "train_y = label_encoder.fit_transform(word_ls)    # 문자형 변수를 숫자형으로 변경\n",
        "print(train_y)\n",
        "# 원숭이 : 2 , 바나나 : 0 , 사과 : 1 , 코끼리 : 3 \n",
        "\n",
        "train_y = train_y.reshape(len(train_y),1)\n",
        "#print(train_y)\n",
        "\n",
        "train_y = onehot_encoder.fit_transform(train_y)\n",
        "train_y.toarray()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 0 1 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6TDMDuDPl7q",
        "colab_type": "text"
      },
      "source": [
        "Word2Vec\n",
        "\n",
        "it_df : IT 뉴스 \n",
        "\n",
        "culture_df : 문화 뉴스"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scCiXOodQAH-",
        "colab_type": "text"
      },
      "source": [
        "전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XJBLZ0RPU6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Jupyter Notebook 코드 \n",
        "# Google drive에서 파일 불러오는것...ㅎㅎㅎ\n",
        "# 데이터 불러오기\n",
        "import pandas as pd\n",
        "it_df = pd.read_csv('2_word_embedding_it.csv').dropna() # 디폴트로 NaN이 1개라도 포함되면 해당 행이 삭제\n",
        "culture_df = pd.read_csv('2_word_embedding_culture.csv').dropna()\n",
        "\n",
        "# word2vec을 하기 위한 전처리\n",
        "# it_df와 culture_df의 컬럼 '1'의 토큰을 리스트 형태로 변경\n",
        "it_token_ls = list(it_df.loc[:,'1']) \n",
        "culture_token_ls = list(culture_df.loc[:,'1'])\n",
        "\n",
        "total_token_ls = it_token_ls + culture_token_ls  # it_df의 리스트와 culture_df의 리스트를 한개로 합침\n",
        "\n",
        "# 리스트의 값을 ','로 분리\n",
        "total_token_ls = [tokens.split(',') for tokens in total_token_ls]\n",
        "print(total_token_ls[0][:10])\n",
        "['배', '정회', '신임', '과학기술', '일자리', '진흥', '원장', '아시아', '경제', '이민']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZsZ8IMrQGCc",
        "colab_type": "text"
      },
      "source": [
        "gensim Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gbMr7TdP8sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gensim이라는 패키지에 word2Vec 클래스 사용\n",
        "from gensim.models import Word2Vec\n",
        "word2vec = Word2Vec(\n",
        "    sentences = total_token_ls,  # 학습시킬 문장\n",
        "    size = 10,                  # 임베딩된 단어 벡터의 차원 크기\n",
        "    alpha = 0.025,               # 학습률(Learning rate)\n",
        "    min_count=2,                 # 2번 미만 등장한 단어는 제외\n",
        "    window = 8,                  # 문맥의 크기 (window_size)\n",
        "    sample = 0.001,              # sub-sampling\n",
        "    sg = 1,                      # 0: CBOW, 1: Skip-gram\n",
        "    iter = 10                    # 전체 문장 반복학습 횟수(epoch)\n",
        "    )\n",
        "\n",
        "# '인공'의 단어 임베딩 \n",
        "word_embedding = word2vec.wv.__getitem__('인공')\n",
        "print(word_embedding)\n",
        "\n",
        "\n",
        "# '인공'과 유사도가 높은 단어\n",
        "word_similar_1 = word2vec.wv.most_similar('인공')\n",
        "print(word_similar_1)\n",
        "\n",
        "#'데이터'와 유사도가 높은 단어\n",
        "word_similar_2 = word2vec.wv.most_similar('데이터')\n",
        "print(word_similar_2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfPCWYvG9uUS",
        "colab_type": "text"
      },
      "source": [
        "FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZKXusAc9tcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.word2vec import Text8Corpus\n",
        "from gensim.models import FastText\n",
        "\n",
        "ft_model = FastText(Text8Corpus('text.txt'),  \n",
        "                                  size=10,                 # 임베딩된 단어 벡터의 차원 크기\n",
        "                                  window=8,                 # 문맥의 크기 (window_size)\n",
        "                                  min_count=2,            # 2번 미만 등장한 단어는 제외\n",
        "                                  alpha = 0.025,                    # 학습률(Learning rate)\n",
        "                                  sg = 1,                             # 0: CBOW, 1: Skip-gram\n",
        "                                  iter = 10,              # 전체 문장 반복학습 횟수(epoch)\n",
        "                                  min_n=3, max_n=6)            # 최소, 최대 Ngram 수   \n",
        "\n",
        "# Getting most similar vectors\n",
        "print(ft_model.wv.most_similar('인공'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ziMZL03nWy",
        "colab_type": "text"
      },
      "source": [
        "GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4ep3IXS3c3u",
        "colab_type": "code",
        "outputId": "a59b1f2a-d267-4ae3-95b0-b13e8eabe2b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "!pip install glove_python"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting glove_python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/79/7e7e548dd9dcb741935d031117f4bed133276c2a047aadad42f1552d1771/glove_python-0.1.0.tar.gz (263kB)\n",
            "\r\u001b[K     |█▎                              | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20kB 7.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 30kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 40kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 61kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 71kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 81kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 92kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 102kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 112kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 122kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 133kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 143kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 153kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 163kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 174kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 184kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 194kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 204kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 215kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 225kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 235kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 245kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 256kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 266kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.3.2)\n",
            "Building wheels for collected packages: glove-python\n",
            "  Building wheel for glove-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glove-python: filename=glove_python-0.1.0-cp36-cp36m-linux_x86_64.whl size=702674 sha256=c9477356dad73eab4bfe9a737b913b2916f1d1cd1a10052c2379e27f307d1793\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/4b/6d/10c0d2ad32c9d9d68beec9694a6f0b6e83ab1662a90a089a4b\n",
            "Successfully built glove-python\n",
            "Installing collected packages: glove-python\n",
            "Successfully installed glove-python-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTEChJq13Wta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from glove import Glove\n",
        "from glove import Corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPVirbH63-f1",
        "colab_type": "code",
        "outputId": "4c897577-21cc-4c66-b998-16515c488e5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-b45877ee2c40>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    result = '안성완 인턴기자 asw0727 imaeil com  사진 위메프 홈페이지 캡쳐위메프의  반값특가 가 22일 밤 네티즌들의 관심을 모으고 있다 위메프의  반값특가 는 22일부터 오는 25일까지 진행된다  첫날에는 정각마다 1만 명 선착순 기준으로 50  할인 쿠폰을  이후에는 2시간 간격으로 3천 명에게 제품을 제공할 예정이다 이 쿠폰은  반값특가  말머리가 붙은 상품에만 사용할 수 있다  1원 이상 구매 시 최대 1000원까지 할인되며 한 ID 당 1회만 사용할 수 있다 잠시 후  11시 딜 에서는 여러 가성비 좋은 제품이 선보인다  11시 딜 상품    9900원 100개  더 셰프 보랄 대용량 에어프라이어 6L 6만6900원 1000개  코튼하임 이불 베개 토퍼 3종 세트 2만9900원 2000개  엘리스 순수감촉 생리대 5900원 3000개 몰려드는 소비자들 사이에서 득템을 하기 위해서는 장바구니에 담지 말고 바로 결제로 제품을 구매하는 것이 좋다 이어 다수의 ID를 통한 구매는 제외되며  제3자에게 판매 목적으로 구입 했을 경우 회원자격을 박탈하고 손해배상 청구 대상이 될 수 있다  매일신문   www imaeil com  울산과 경남  경북  강원  제주 등 5개 시도에서 공공 부문 중심 미세먼지 비상저감조치에 들어간다고 환경부가 22일 밝혔다  지난 12 15일 전국적으로 기승을 부린 고농도 미세먼지로 수도권과 부산 등 전국 12개 시도에서 비상저감조치가 시행된 바 있지만 울산 등 5개 시도는 대상에서 빠졌다  22일부터 즉시 시행된 비상저감조치에 따라 울산  경남 등에서는 행정 공공기관 차량 2부제와 공공 사업장 공사장 가동 조정  도로 청소차 운영 확대 등 조치가 단행된다 23일 미세먼지 농도는 호남 영남권에서  나쁨   그 밖의 권역에서  보통  수준을 보일 전망이다  이날 전국은 대체로 맑은 날씨를 보일 것으로 예상된다  이날 아침 최저기온은  8 4도  낮 최고기온은 5 13도로 예보됐다  서울은  2 6도의 기온 분포를 보이겠다  같은 날 밤부터는 북서쪽에서 찬 공기가 유입돼 24일 아침 기온은 다시 큰 폭으로 떨어지겠다    최희석 기자   김희래 기자  매경 뉴스레터  매콤달콤 을 지금 구독하세요 뉴스 이상의 무궁무진한 프리미엄 읽을거리   매일경제   mk co kr  무단전재 및 재배포 금지   한국방송통신대학교 총장 류수노 이하 방송대 가 1월19일  제 1회 KNOU 글로벌 봉사단 이 고엽제 피해자 수용시설인 베트남 하노이 프렌드쉽 빌리지 Friendship Village  봉사활동을 마치고 돌아왔다고 밝혔다 사진 한국방송통신대학교방송대는 나눔과 봉사 문화를 전파하고  학생들의 글로벌 마인드를 함양하여 국제 사회를 선도하는 인재로 양성하기 위해 해외 봉사단을 모집했다고 설명했다  KNOU 글로벌 봉사단은 서류심사와 면접심사를 거쳐 20대부터 70대에 이르는 연령층의 다양한 직업을 가진 학생 11명으로 구성됐다  특히 베트남 현지 봉사인 점을 고려하여 베트남 국적의...\n\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjSJkWHS3Xic",
        "colab_type": "code",
        "outputId": "3962764d-824e-4ff6-87ac-af2f4032e7e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "corpus = Corpus() \n",
        "corpus.fit(result, window=5)\n",
        "# 훈련 데이터로부터 GloVe에서 사용할 동시 등장 행렬 생성\n",
        "\n",
        "glove = Glove(no_components=100, learning_rate=0.05)\n",
        "glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "# 학습에 이용할 쓰레드의 개수는 4로 설정, 에포크는 20."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3d6286573680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# 훈련 데이터로부터 GloVe에서 사용할 동시 등장 행렬 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mglove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKaYr_Yy3vgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}